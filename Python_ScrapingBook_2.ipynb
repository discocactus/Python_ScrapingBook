{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chapter 2-4 webページを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = urlopen('http://sample.scraping-book.com/dp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f.getheader('Content-Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile urlopen_encoding.py\n",
    "\n",
    "import sys\n",
    "from urllib.request import urlopen\n",
    "\n",
    "f = urlopen('http://sample.scraping-book.com/dp')\n",
    "encoding = f.info().get_content_charset(failobj=\"utf-8\")\n",
    "print('encoding:', encoding, file=sys.stderr)\n",
    "\n",
    "text = f.read().decode(encoding)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python urlopen_encoding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python urlopen_encoding.py > dp.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile urlopen_meta.py\n",
    "\n",
    "import re\n",
    "import sys\n",
    "from urllib.request import urlopen\n",
    "\n",
    "f = urlopen('http://sample.scraping-book.com/dp')\n",
    "bytes_content = f.read()\n",
    "\n",
    "scanned_text = bytes_content[:1024].decode('ascii', errors='replace')\n",
    "\n",
    "match = re.search(r'charset=[\"\\']?([\\w-]+)', scanned_text)\n",
    "if match:\n",
    "    encoding = match.group(1)\n",
    "else:\n",
    "    encoding = 'utf-8'\n",
    "\n",
    "print('encoding:', encoding, file=sys.stderr)\n",
    "\n",
    "text = bytes_content.decode(encoding)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python urlopen_meta.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chapter 2-5 webページからデータを抜き出す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 正規表現によるスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search(r'a.*c', 'abc123DEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re.search(r'a.*d', 'abc123DEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.search(r'a.*d', 'abc123DEF', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = re.search(r'a(.*)c', 'abc123DEF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.findall(r'\\w{2,}', 'This is a pen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "re.sub(r'\\w{2,}', 'That', 'This is a pen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%writefile scrape_re.py\n",
    "\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "with open('dp.html') as f:\n",
    "    html = f.read()\n",
    "    \n",
    "for partial_html in re.findall(r'<a itemprop=\"url\".*?</ul>\\s*</a></li>', html, re.DOTALL):\n",
    "    url = re.search(r'<a itemprop=\"url\" href=\"(.*?)\">', partial_html).group(1)\n",
    "    url = 'http://sample.scraping-book.com' + url\n",
    "    \n",
    "    title = re.search(r'<p itemprop=\"name\".*?</p>', partial_html).group(0)\n",
    "    title = title.replace('<br/>', ' ')\n",
    "    title = re.sub(r'<.*?>', '', title)\n",
    "    title = unescape(title)\n",
    "    \n",
    "    print(url, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python scrape_re.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XML(RSS)のスクレイピング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-08-23 23:08:37--  http://gihyo.jp/feed/rss2\n",
      "Resolving gihyo.jp... 104.20.34.31, 104.20.33.31, 2400:cb00:2048:1::6814:211f, ...\n",
      "Connecting to gihyo.jp|104.20.34.31|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/xml]\n",
      "Saving to: ‘rss2.xml’\n",
      "\n",
      "rss2.xml                [ <=>                ]  13.33K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2017-08-23 23:08:37 (168 KB/s) - ‘rss2.xml’ saved [13646]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://gihyo.jp/feed/rss2 -O rss2.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting scrape_rss.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scrape_rss.py\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "tree = ElementTree.parse('rss2.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "for item in root.findall('channel/item'):\n",
    "    title = item.find('title').text\n",
    "    url = item.find('link').text\n",
    "    print(url, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://gihyo.jp/lifestyle/clip/01/everyday-cat/201708/23 2017年8月23日　座るしろくろこ ── 技評ねこ部通信\r\n",
      "http://gihyo.jp/admin/serial/01/ubuntu-recipe/0485 第485回　aptlyで本格的なパッケージリポジトリを作る ── Ubuntu Weekly Recipe\r\n",
      "http://gihyo.jp/dev/serial/01/perl-hackers-hub/004403 第44回　LINE Messaging APIで作るchatbot―LINE::Bot::APIとngrokでお手軽に！（3） ── Perl Hackers Hub\r\n",
      "http://gihyo.jp/lifestyle/clip/01/everyday-cat/201708/22 2017年8月22日　宮古島のしろくろこ ── 技評ねこ部通信\r\n",
      "http://gihyo.jp/design/serial/01/ui-design-unsung/0002 第2回　エラーと確認―スムーズな手続きを実現するには ── 縁の下のUIデザイン―少しの工夫で大きな改善！\r\n",
      "http://gihyo.jp/dev/serial/01/perl-hackers-hub/004402 第44回　LINE Messaging APIで作るchatbot―LINE::Bot::APIとngrokでお手軽に！（2） ── Perl Hackers Hub\r\n",
      "http://gihyo.jp/dev/serial/01/mysql-road-construction-news/0052 第52回　MySQLのパーティショニング機能 ── MySQL道普請便り\r\n",
      "http://gihyo.jp/lifestyle/clip/01/everyday-cat/201708/21 2017年8月21日　見上げてごらん。しろくろこを！ ── 技評ねこ部通信\r\n",
      "http://gihyo.jp/lifestyle/serial/01/engineer-x-manage/0003 第3回　チームづくりにおけるエンジニア出身社長の強みとは ── エンジニアと経営のクロスオーバー\r\n",
      "http://gihyo.jp/dev/serial/01/perl-hackers-hub/004401 第44回　LINE Messaging APIで作るchatbot―LINE::Bot::APIとngrokでお手軽に！（1） ── Perl Hackers Hub\r\n",
      "http://gihyo.jp/admin/clip/01/linux_dt/201708/18 2017年8月18日　NVIDIA，Tesla GPUに対応した仮想化ソフトウェアを発表 ── Linux Daily Topics\r\n",
      "http://gihyo.jp/lifestyle/clip/01/everyday-cat/201708/18 2017年8月18日　少女黒仮面伝説再び！ ── 技評ねこ部通信\r\n",
      "http://gihyo.jp/dev/serial/01/teamdev-toolstrategy/0018 第18回　Subversionではだめなんですか！？（後編） ── うまくいくチーム開発のツール戦略\r\n",
      "http://gihyo.jp/dev/serial/01/swift-introduction/0029 第29回　順序どおり問題を制する ── 書いて覚えるSwift入門\r\n",
      "http://gihyo.jp/dev/serial/01/funny-play/0116 第116回　ちょっと変更のつもりが… ── きたみりゅうじの聞かせて珍プレー\r\n",
      "http://gihyo.jp/lifestyle/clip/01/everyday-cat/201708/17 2017年8月17日　足だけ白いしろくろこ ── 技評ねこ部通信\r\n",
      "http://gihyo.jp/admin/clip/01/linux_dt/201708/17 2017年8月17日　Debian，24歳になる ―8月16日はDebian Day ── Linux Daily Topics\r\n",
      "http://gihyo.jp/admin/serial/01/ubuntu-recipe/0484 第484回　UbuntuとOpenNebulaでKVMとLXDのインスタンスを起ち上げてみよう ── Ubuntu Weekly Recipe\r\n",
      "http://gihyo.jp/lifestyle/clip/01/awt/201708/17 2017年8月第3週　Android O，ストリーミング・アップデートに対応ほか ── Android Weekly Topics\r\n",
      "http://gihyo.jp/design/clip/01/weekly-web-tech/201708/17 2017年8月第3週号 1位は，手痛いミスから学ぶユーザーインターフェイス10の法則，気になるネタは，Instagramのライブ配信に友人を招待--新機能が追加へ ── 週刊Webテク通信\r\n"
     ]
    }
   ],
   "source": [
    "!python scrape_rss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chapter 2-6 データを保存する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CSV形式での保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing save_csv_join.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save_csv_join.py\n",
    "\n",
    "print('rank,city,population')\n",
    "\n",
    "print(','.join(['1', '上海', '24150000']))\n",
    "print(','.join(['2', 'カラチ', '23500000']))\n",
    "print(','.join(['3', '北京', '21516000']))\n",
    "print(','.join(['4', '天津', '14722100']))\n",
    "print(','.join(['5', 'イスタンブル', '14160467']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank,city,population\r\n",
      "1,上海,24150000\r\n",
      "2,カラチ,23500000\r\n",
      "3,北京,21516000\r\n",
      "4,天津,14722100\r\n",
      "5,イスタンブル,14160467\r\n"
     ]
    }
   ],
   "source": [
    "!python save_csv_join.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python save_csv_join.py > top_cities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting save_csv.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save_csv.py\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('top_cities_2.csv', 'w', newline='')as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['rank', 'city', 'population'])\n",
    "    writer.writerows([\n",
    "        [1, '上海', 24150000],\n",
    "        [2, 'カラチ', 23500000],\n",
    "        [3, '北京', 21516000],\n",
    "        [4, '天津', 14722100],\n",
    "        [5, 'イスタンブル', 14160467],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!python save_csv.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting save_csv_dict.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save_csv_dict.py\n",
    "\n",
    "import csv\n",
    "\n",
    "with open('top_cities_3.csv', 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, ['rank', 'city', 'population'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([\n",
    "        {'rank': 1, 'city': '上海', 'population': 24150000},\n",
    "        {'rank': 2, 'city': 'カラチ', 'population': 23500000},\n",
    "        {'rank': 3, 'city': '北京', 'population': 21516000},\n",
    "        {'rank': 4, 'city': '天津', 'population': 14722100},\n",
    "        {'rank': 5, 'city': 'イスタンブル', 'population': 14160467},\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python save_csv_dict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UTF-8'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# デフォルト(環境依存)のエンコーディングの値を取得する\n",
    "import locale\n",
    "\n",
    "locale.getpreferredencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# JSON形式での保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing save_json.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save_json.py\n",
    "\n",
    "import json\n",
    "\n",
    "cities = [\n",
    "    {'rank': 1, 'city': '上海', 'population': 24150000},\n",
    "    {'rank': 2, 'city': 'カラチ', 'population': 23500000},\n",
    "    {'rank': 3, 'city': '北京', 'population': 21516000},\n",
    "    {'rank': 4, 'city': '天津', 'population': 14722100},\n",
    "    {'rank': 5, 'city': 'イスタンブル', 'population': 14160467},\n",
    "]\n",
    "\n",
    "print(json.dumps(cities, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\r\n",
      "  {\r\n",
      "    \"rank\": 1,\r\n",
      "    \"city\": \"上海\",\r\n",
      "    \"population\": 24150000\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"rank\": 2,\r\n",
      "    \"city\": \"カラチ\",\r\n",
      "    \"population\": 23500000\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"rank\": 3,\r\n",
      "    \"city\": \"北京\",\r\n",
      "    \"population\": 21516000\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"rank\": 4,\r\n",
      "    \"city\": \"天津\",\r\n",
      "    \"population\": 14722100\r\n",
      "  },\r\n",
      "  {\r\n",
      "    \"rank\": 5,\r\n",
      "    \"city\": \"イスタンブル\",\r\n",
      "    \"population\": 14160467\r\n",
      "  }\r\n",
      "]\r\n"
     ]
    }
   ],
   "source": [
    "!python save_json.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing save_json_file.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save_json_file.py\n",
    "\n",
    "import json\n",
    "\n",
    "cities = [\n",
    "    {'rank': 1, 'city': '上海', 'population': 24150000},\n",
    "    {'rank': 2, 'city': 'カラチ', 'population': 23500000},\n",
    "    {'rank': 3, 'city': '北京', 'population': 21516000},\n",
    "    {'rank': 4, 'city': '天津', 'population': 14722100},\n",
    "    {'rank': 5, 'city': 'イスタンブル', 'population': 14160467},\n",
    "]\n",
    "\n",
    "with open('top_cities.json', 'w') as f:\n",
    "    json.dump(cities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!python save_json_file.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データベース(SQLite3)への保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing save_sqlite3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile save_sqlite3.py\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('top_cities.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "c.execute('DROP TABLE IF EXISTS cities')\n",
    "c.execute('''\n",
    "    CREATE TABLE cities (\n",
    "        rank integer,\n",
    "        city text,\n",
    "        population integer\n",
    "    )\n",
    "''')\n",
    "\n",
    "# execute()メソッドの第2引数にはSQL文のパラメーターのリストを指定できる\n",
    "# パラメーターで置き換える場所(プレースホルダー)は ? で指定する\n",
    "c.execute('INSERT INTO cities VALUES (?, ?, ?)', (1, '上海', 24150000))\n",
    "\n",
    "# パラメーターが辞書の場合、プレースホルダーは :キー名 で指定する\n",
    "c.execute('INSERT INTO cities VALUES (:rank, :city, :population)',\n",
    "         {'rank': 2, 'city': 'カラチ', 'population': 23500000})\n",
    "\n",
    "# executemany()メソッドでは、複数のパラメーターをリストで指定できる\n",
    "# パラメーターの数(ここでは3つ)のSQLを順に実行できる\n",
    "c.executemany('INSERT INTO cities VALUES (:rank, :city, :population)', [\n",
    "    {'rank': 3, 'city': '北京', 'population': 21516000},\n",
    "    {'rank': 4, 'city': '天津', 'population': 14722100},\n",
    "    {'rank': 5, 'city': 'イスタンブル', 'population': 14160467},\n",
    "])\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "c.execute('SELECT * FROM cities')\n",
    "for row in c.fetchall():\n",
    "    print(row)\n",
    "    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, '上海', 24150000)\r\n",
      "(2, 'カラチ', 23500000)\r\n",
      "(3, '北京', 21516000)\r\n",
      "(4, '天津', 14722100)\r\n",
      "(5, 'イスタンブル', 14160467)\r\n"
     ]
    }
   ],
   "source": [
    "!python save_sqlite3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1|上海|24150000\r\n",
      "2|カラチ|23500000\r\n",
      "3|北京|21516000\r\n",
      "4|天津|14722100\r\n",
      "5|イスタンブル|14160467\r\n"
     ]
    }
   ],
   "source": [
    "!sqlite3 top_cities.db 'SELECT * FROM cities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# chapter 2-7 Pythonによるスクレイピングの流れ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting python_scraper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile python_scraper.py\n",
    "\n",
    "import re\n",
    "import sqlite3\n",
    "from urllib.request import urlopen\n",
    "from html import unescape\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    メインの処理。fetch(), scrape(), save()の3つの関数を呼び出す。\n",
    "    \"\"\"\n",
    "    \n",
    "    html = fetch('http://sample.scraping-book.com/dp')\n",
    "    books = scrape(html)\n",
    "    save('books.db', books)\n",
    "\n",
    "\n",
    "def fetch(url):\n",
    "    \"\"\"\n",
    "    引数urlで与えられたURLのwebページを取得する。\n",
    "    webページのエンコーディングはContent-Typeヘッダーから取得する。\n",
    "    戻り値: str型のHTML\n",
    "    \"\"\"\n",
    "    \n",
    "    f = urlopen(url)\n",
    "    # HTTPヘッダーからエンコーディングを取得する(明示されていない場合はutf-8とする)。\n",
    "    encoding = f.info().get_content_charset(failobj=\"utf-8\")\n",
    "    html = f.read().decode(encoding) # 得られたエンコーディングを指定して文字列にデコードする。\n",
    "    \n",
    "    return(html)\n",
    "\n",
    "\n",
    "def scrape(html):\n",
    "    \"\"\"\n",
    "    引数htmlで与えられたHTMLから正規表現で書籍の情報を抜き出す。\n",
    "    戻り値: 書籍(dict)のリスト\n",
    "    \"\"\"\n",
    "    \n",
    "    books = []\n",
    "    for partial_html in re.findall(r'<a itemprop=\"url\".*?</ul>\\s*</a></li>', html, re.DOTALL):\n",
    "        # 書籍のURLは itemprop=\"url\" という属性を持つa要素のhref属性から取得する。\n",
    "        url = re.search(r'<a itemprop=\"url\" href=\"(.*?)\">', partial_html).group(1)\n",
    "        url = 'http://sample.scraping-book.com/dp' + url # / で始まっているのでドメイン名などを追加する。\n",
    "        \n",
    "        # 書籍のタイトルは itemprop=\"name\" という属性を持つp要素から取得する。\n",
    "        title = re.search(r'<p itemprop=\"name\".*?</p>', partial_html).group(0)\n",
    "        title = re.sub(r'<.*?>', '', title) # タグを取り除く。\n",
    "        title = unescape(title) # 文字参照を元に戻す。\n",
    "        \n",
    "        books.append({'url': url, 'title': title})\n",
    "        \n",
    "    return(books)\n",
    "\n",
    "\n",
    "def save(db_path, books):\n",
    "    \"\"\"\n",
    "    引数booksで与えられた書籍のリストをSQLiteデータベースに保存する。\n",
    "    データベースのパスは引数db_pathで与えられる。\n",
    "    戻り値: なし\n",
    "    \"\"\"\n",
    "    \n",
    "    conn = sqlite3.connect(db_path) # データベースを開き、コネクションを取得する。\n",
    "    \n",
    "    c = conn.cursor() # カーソルを取得する。\n",
    "    # execute()メソッドでSQL文を実行する。\n",
    "    # このスクリプトを何回実行しても同じ結果になるようにするため、booksテーブルが存在する場合は削除する。\n",
    "    c.execute('DROP TABLE IF EXISTS books')\n",
    "    # booksテーブルを作成する。\n",
    "    c.execute('''\n",
    "        CREATE TABLE books (\n",
    "            title text,\n",
    "            url text\n",
    "        )\n",
    "    ''')\n",
    "    \n",
    "    # executemany()メソッドでは、複数のパラメーターをリストで指定できる。\n",
    "    c.executemany('INSERT INTO books VALUES (:title, :url)', books)\n",
    "    \n",
    "    conn.commit() # 変数をコミット(保存)する。\n",
    "    conn.close() # コネクションを閉じる。\n",
    "    \n",
    "    \n",
    "# pythonコマンドで実行された場合にmain()関数を呼び出す。これはモジュールとして他のファイルから\n",
    "# インポートされた時に、main()関数が実行されないようにするための、Pythonにおける一般的なイディオム。\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 実行\n",
    "!python python_scraper.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "これからはじめるプログラミング 作って覚える基礎の基礎|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8336-7\r\n",
      "情報処理技術者試験 平成28年度【秋期】情報セキュリティマネジメント パーフェクトラーニング過去問題集|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8337-4\r\n",
      "大人の自由時間（大人の自由時間mini） 水泳のきれいなカラダをつくる～スリムな逆三角形になる！ドライランドトレーニング|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8338-1\r\n",
      "30レッスン 30レッスンで絶対合格！ Microsoft Office Specialist PowerPoint 2013 テキスト＋問題集|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8346-6\r\n",
      "ゼロからはじめる ゼロからはじめる海外旅行でスマホ活用 スマートガイド|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8334-3\r\n",
      "今すぐ使えるかんたんmini 今すぐ使えるかんたんminiCD&DVD 作成超入門［Windows 10対応版］|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8335-0\r\n",
      "大きな字でわかりやすい 大きな字でわかりやすいワード2016入門|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8325-1\r\n",
      "大きな字でわかりやすい 大きな字でわかりやすいエクセル2016 入門|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8322-0\r\n",
      "今すぐ使えるかんたん 今すぐ使えるかんたんぜったいデキます！ デジカメ写真活用術［Windows 10対応版］|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8323-7\r\n",
      "Software Design 2016年8月号|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8119-6\r\n",
      "無料ではじめるBlender CGイラストテクニック～3DCGの考え方としくみがしっかりわかる|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8333-6\r\n",
      "小さなお店＆会社の WordPress超入門―初めてでも安心！思いどおりのホームページを作ろう！|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8324-4\r\n",
      "WEB+DB PRESS plus Atom実践入門──進化し続けるハッカブルなエディタ|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8302-2\r\n",
      "アウトライナー実践入門～「書く・考える・生活する」創造的アウトライン・プロセッシングの技術〜|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8301-5\r\n",
      "ゼロからはじめる ゼロからはじめるドコモGalaxy S7 edge SC-02H スマートガイド|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8297-1\r\n",
      "Excelのムカムカ！が一瞬でなくなる使い方～表計算・資料作成のストレスを最小限に！|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8255-9\r\n",
      "Wordのムカムカ！が一瞬でなくなる使い方～文章・資料作成のストレスを最小限に！|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8258-2\r\n",
      "生物ミステリー（生物ミステリー プロ） そもそも島に進化あり|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8319-0\r\n",
      "大人の自由時間（大人の自由時間mini） 山歩きスタートブック～道具と歩き方がわかる，行きたいコースが見つかる|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8318-3\r\n",
      "平成28-29年度 基本情報技術者 試験によくでる問題集【午後】|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8317-6\r\n",
      "大人の自由時間（大人の自由時間mini） あきらめないランニング～楽しいランのはじめかた，続けかた|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8300-8\r\n",
      "Excel＆Access連携 実践ガイド～仕事の現場で即使える|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8299-5\r\n",
      "大人の自由時間（大人の自由時間mini） もう一度バイクに乗ろう！～羨望されるオトナのライダーになりたい人に|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8296-4\r\n",
      "Slack入門[ChatOpsによるチーム開発の効率化]|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8292-6\r\n",
      "パソコン入門5冊分！＜Windows 10入門＋Windows 10活用＋インターネット＆メール＋Word＋Excel＞|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8273-5\r\n",
      "人気ハンドメイド作家になりたい人が読む本|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8295-7\r\n",
      "今すぐ使えるかんたんEx 今すぐ使えるかんたんExヤフオク！ 本気で儲ける！ プロ技セレクション|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8288-9\r\n",
      "今すぐ使えるかんたんmini 今すぐ使えるかんたんminiAccess 2016 基本技|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8289-6\r\n",
      "ゼロからはじめる ゼロからはじめるOneNote 2016／2013 スマートガイド|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8290-2\r\n",
      "ゼロからはじめる ゼロからはじめるau Galaxy S7 edge SCV33 スマートガイド|http://sample.scraping-book.com/dp/dp/ebook/2016/978-4-7741-8291-9\r\n"
     ]
    }
   ],
   "source": [
    "# sqlite3コマンドで実行結果を確認\n",
    "!sqlite3 books.db 'SELECT * FROM books'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
